{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Taylor Green Vortex\n",
    "\n",
    "## Overview\n",
    "\n",
    "In fluid dynamics, the Taylor–Green vortex is an unsteady flow of a decaying vortex, which has an exact closed form solution of the incompressible Navier–Stokes equations in Cartesian coordinates. It is named after the British physicist and mathematician Geoffrey Ingram Taylor and his collaborator A. E. Green.\n",
    "\n",
    "Physics-informed Neural Networks (PINNs) provides a new method for quickly solving complex fluid problems by using loss functions that approximate governing equations coupled with simple network configurations. In this case, the data-driven characteristic of neural network is used along with `PINNs` to solve the 2D taylor green vortex problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "The Navier-Stokes equation, referred to as `N-S` equation, is a classical partial differential equation in the field of fluid mechanics. In the case of viscous incompressibility, the dimensionless `N-S` equation has the following form:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u} {\\partial t} + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y} = - \\frac{\\partial p}{\\partial x} + \\frac{1} {Re} (\\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial v} {\\partial t} + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} = - \\frac{\\partial p}{\\partial y} + \\frac{1} {Re} (\\frac{\\partial^2v}{\\partial x^2} + \\frac{\\partial^2v}{\\partial y^2})\n",
    "$$\n",
    "\n",
    "where `Re` stands for Reynolds number.\n",
    "\n",
    "In this case, the PINNs method is used to learn the mapping from the location and time to flow field quantities to solve the `N-S` equation.\n",
    "\n",
    "$$\n",
    "(x, y, t) \\mapsto (u, v, p)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technology Path\n",
    "\n",
    "MindFlow solves the problem as follows:\n",
    "\n",
    "1. Training Dataset Construction.\n",
    "2. Model Construction.\n",
    "3. Multi-task Learning for Adaptive Losses\n",
    "4. Optimizer.\n",
    "5. NavierStokes2D.\n",
    "6. Model Training.\n",
    "7. Model Evaluation and Visualization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sympy\n",
    "import mindspore\n",
    "from mindspore import context, nn, ops, jit, set_seed\n",
    "from mindspore import numpy as mnp\n",
    "\n",
    "from mindflow.cell import MultiScaleFCCell\n",
    "from mindflow.loss import MTLWeightedLossCell\n",
    "from mindflow.utils import load_yaml_config\n",
    "from mindflow.pde import NavierStokes, sympy_to_mindspore\n",
    "\n",
    "from src import create_training_dataset, create_test_dataset, calculate_l2_error, NavierStokes2D\n",
    "\n",
    "set_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\", device_id=0, save_graphs=False)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "config = load_yaml_config('taylor_green_2D.yaml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction\n",
    "\n",
    "Training dataset is imported through function _create_train_dataset_, contains domain points, initial condition points and boundary condition point. All datasets are sampled by APIs from mindflow.geometry.\n",
    "\n",
    "Test dataset is imported through function _create_test_dataset_. In this case, the exact solution used to construct test dataset is given by **J Kim, P Moin,Application of a fractional-step method to incompressible Navier-Stokes equations,Journal of Computational Physics,Volume 59, Issue 2,1985**.\n",
    "\n",
    "$$\n",
    "u(x,y,t) = -cos(x)sin(y)e^{-2t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v(x,y,t) = sin(x)cos(y)e^{-2t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x,y,t) = -0.25(cos(2x)+cos(2y))e^{-4t}\n",
    "$$\n",
    "\n",
    "The computation is carried out in the domain of $ 0 \\leq  x,y \\leq 2\\pi$,\n",
    "and $ 0 \\leq t \\leq 2$. The Reynolds number Re is equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "taylor_dataset = create_training_dataset(config)\n",
    "train_dataset = taylor_dataset.create_dataset(batch_size=config[\"train_batch_size\"],\n",
    "                                              shuffle=True,\n",
    "                                              prebatched_data=True,\n",
    "                                              drop_remainder=True)\n",
    "\n",
    "# create test dataset\n",
    "inputs, label = create_test_dataset(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction\n",
    "\n",
    "This example uses a simple fully-connected network with a depth of 6 layers and the activation function is the `tanh` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_min = np.array(config[\"geometry\"][\"coord_min\"] + [config[\"geometry\"][\"time_min\"]]).astype(np.float32)\n",
    "coord_max = np.array(config[\"geometry\"][\"coord_max\"] + [config[\"geometry\"][\"time_max\"]]).astype(np.float32)\n",
    "input_center = list(0.5 * (coord_max + coord_min))\n",
    "input_scale = list(2.0 / (coord_max - coord_min))\n",
    "\n",
    "model = MultiScaleFCCell(in_channels=config[\"model\"][\"in_channels\"],\n",
    "                         out_channels=config[\"model\"][\"out_channels\"],\n",
    "                         layers=config[\"model\"][\"layers\"],\n",
    "                         neurons=config[\"model\"][\"neurons\"],\n",
    "                         residual=config[\"model\"][\"residual\"],\n",
    "                         act='tanh',\n",
    "                         num_scales=1,\n",
    "                         input_scale=input_scale,\n",
    "                         input_center=input_center)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task learning for adaptive losses\n",
    "\n",
    "The PINNs method needs to optimize multiple losses at the same time, and brings challenges to the optimization process. Here, we adopt the uncertainty weighting algorithm proposed in **Kendall, Alex, Yarin Gal, and Roberto Cipolla. \"Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.\" CVPR, 2018.** to dynamically adjust the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use MtlWeightedLossCell, num loss: 3\n"
     ]
    }
   ],
   "source": [
    "mtl = MTLWeightedLossCell(num_losses=taylor_dataset.num_dataset)\n",
    "print(\"Use MtlWeightedLossCell, num loss: {}\".format(mtl.num_losses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.trainable_params() + mtl.trainable_params()\n",
    "optimizer = nn.Adam(params, learning_rate=config[\"optimizer\"][\"initial_lr\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NavierStokes2D\n",
    "\n",
    "The following `NavierStokes2D` defines the navier-stokes' problem. Specifically, it includes 3 parts: governing equation, initial condition and boundary conditions. Initial condition and boundary conditions are constructed by the exact solution mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavierStokes2D(NavierStokes):\n",
    "    def __init__(self, model, re=100, loss_fn=nn.MSELoss()):\n",
    "        super(NavierStokes2D, self).__init__(model, re=re, loss_fn=loss_fn)\n",
    "        self.ic_nodes = sympy_to_mindspore(self.ic(), self.in_vars, self.out_vars)\n",
    "        self.bc_nodes = sympy_to_mindspore(self.bc(), self.in_vars, self.out_vars)\n",
    "\n",
    "    def ic(self):\n",
    "        \"\"\"\n",
    "        Define initial condition equations based on sympy, abstract method.\n",
    "        \"\"\"\n",
    "        ic_u = self.u + sympy.cos(self.x) * sympy.sin(self.y)\n",
    "        ic_v = self.v - sympy.sin(self.x) * sympy.cos(self.y)\n",
    "        ic_p = self.p + 0.25 * (sympy.cos(2*self.x) + sympy.cos(2*self.y))\n",
    "        equations = {\"ic_u\": ic_u, \"ic_v\": ic_v, \"ic_p\": ic_p}\n",
    "        return equations\n",
    "\n",
    "    def bc(self):\n",
    "        \"\"\"\n",
    "        Define boundary condition equations based on sympy, abstract method.\n",
    "        \"\"\"\n",
    "        bc_u = self.u + sympy.cos(self.x) * sympy.sin(self.y) * sympy.exp(-2*self.t)\n",
    "        bc_v = self.v - sympy.sin(self.x) * sympy.cos(self.y) * sympy.exp(-2*self.t)\n",
    "        bc_p = self.p + 0.25 * (sympy.cos(2*self.x) + sympy.cos(2*self.y)) * sympy.exp(-4*self.t)\n",
    "        equations = {\"bc_u\": bc_u, \"bc_v\": bc_v, \"bc_p\": bc_p}\n",
    "        return equations\n",
    "\n",
    "    def get_loss(self, pde_data, ic_data, bc_data):\n",
    "        \"\"\"\n",
    "        Compute loss of 3 parts: governing equation, initial condition and boundary conditions.\n",
    "\n",
    "        Args:\n",
    "            pde_data (Tensor): the input data of governing equations.\n",
    "            ic_data (Tensor): the input data of initial condition.\n",
    "            bc_data (Tensor): the input data of boundary condition.\n",
    "        \"\"\"\n",
    "        pde_res = self.parse_node(self.pde_nodes, inputs=pde_data)\n",
    "        pde_residual = ops.Concat(1)(pde_res)\n",
    "        pde_loss = self.loss_fn(pde_residual, mnp.zeros_like(pde_residual))\n",
    "\n",
    "        ic_res = self.parse_node(self.ic_nodes, inputs=ic_data)\n",
    "        ic_residual = ops.Concat(1)(ic_res)\n",
    "        ic_loss = self.loss_fn(ic_residual, mnp.zeros_like(ic_residual))\n",
    "\n",
    "        bc_res = self.parse_node(self.bc_nodes, inputs=bc_data)\n",
    "        bc_residual = ops.Concat(1)(bc_res)\n",
    "        bc_loss = self.loss_fn(bc_residual, mnp.zeros_like(bc_residual))\n",
    "\n",
    "        return pde_loss + ic_loss + bc_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "With **MindSpore version >= 2.0.0**, we can use the functional programming for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    problem = NavierStokes2D(model, re=config[\"Re\"])\n",
    "\n",
    "    if use_ascend:\n",
    "        from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "        loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "        auto_mixed_precision(model, 'O3')\n",
    "\n",
    "    def forward_fn(pde_data, ic_data, bc_data):\n",
    "        loss = problem.get_loss(pde_data, ic_data, bc_data)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.scale(loss)\n",
    "        return loss\n",
    "\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "\n",
    "    @jit\n",
    "    def train_step(pde_data, ic_data, bc_data):\n",
    "        loss, grads = grad_fn(pde_data, ic_data, bc_data)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.unscale(loss)\n",
    "            if all_finite(grads):\n",
    "                grads = loss_scaler.unscale(grads)\n",
    "                loss = ops.depend(loss, optimizer(grads))\n",
    "        else:\n",
    "            loss = ops.depend(loss, optimizer(grads))\n",
    "        return loss\n",
    "\n",
    "    steps = config[\"train_steps\"]\n",
    "\n",
    "    sink_process = mindspore.data_sink(train_step, train_dataset, sink_size=1)\n",
    "    model.set_train()\n",
    "    for step in range(steps + 1):\n",
    "        local_time_beg = time.time()\n",
    "        cur_loss = sink_process()\n",
    "        if step % 1000 == 0:\n",
    "            print(f\"loss: {cur_loss.asnumpy():>7f}\")\n",
    "            print(\"step: {}, time elapsed: {}ms\".format(step, (time.time() - local_time_beg) * 1000))\n",
    "            calculate_l2_error(model, inputs, label, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_beg = time.time()\n",
    "train()\n",
    "print(\"End-to-End total time: {} s\".format(time.time() - time_beg))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "check training dataset size:  128\n",
    "Use MtlWeightedLossCell, num loss: 3\n",
    "momentum_x: u(x, y, t)*Derivative(u(x, y, t), x) + v(x, y, t)*Derivative(u(x, y, t), y) + Derivative(p(x, y, t), x) + Derivative(u(x, y, t), t) - 1.0*Derivative(u(x, y, t), (x, 2)) - 1.0*Derivative(u(x, y, t), (y, 2))\n",
    "    Item numbers of current derivative formula nodes: 6\n",
    "momentum_y: u(x, y, t)*Derivative(v(x, y, t), x) + v(x, y, t)*Derivative(v(x, y, t), y) + Derivative(p(x, y, t), y) + Derivative(v(x, y, t), t) - 1.0*Derivative(v(x, y, t), (x, 2)) - 1.0*Derivative(v(x, y, t), (y, 2))\n",
    "    Item numbers of current derivative formula nodes: 6\n",
    "continuty: Derivative(u(x, y, t), x) + Derivative(v(x, y, t), y)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "ic_u: u(x, y, t) + sin(y)*cos(x)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "ic_v: v(x, y, t) - sin(x)*cos(y)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "ic_p: p(x, y, t) + 0.25*cos(2*x) + 0.25*cos(2*y)\n",
    "    Item numbers of current derivative formula nodes: 3\n",
    "bc_u: u(x, y, t) + exp(-2*t)*sin(y)*cos(x)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "bc_v: v(x, y, t) - exp(-2*t)*sin(x)*cos(y)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "bc_p: p(x, y, t) + 0.25*exp(-4*t)*cos(2*x) + 0.25*exp(-4*t)*cos(2*y)\n",
    "    Item numbers of current derivative formula nodes: 3\n",
    "loss: 0.218985\n",
    "step: 0, time elapsed: 8551.078081130981ms\n",
    "    predict total time: 395.74146270751953 ms\n",
    "    l2_error, U:  1.0272722185259853 , V:  1.0068734156826729 , P:  1.1140811724988493 , Total:  1.025431141488198\n",
    "==================================================================================================\n",
    "loss: 0.117311\n",
    "step: 1000, time elapsed: 96.29058837890625ms\n",
    "    predict total time: 177.2327423095703 ms\n",
    "    l2_error, U:  0.7230177964964256 , V:  0.7154075373127421 , P:  1.0178466945703284 , Total:  0.7482490912542953\n",
    "==================================================================================================\n",
    "loss: 0.119411\n",
    "step: 2000, time elapsed: 89.85757827758789ms\n",
    "    predict total time: 143.2340145111084 ms\n",
    "    l2_error, U:  0.7112490531604364 , V:  0.7168233752672813 , P:  1.0153781956196177 , Total:  0.7434033117415322\n",
    "==================================================================================================\n",
    "loss: 0.116417\n",
    "step: 3000, time elapsed: 88.8054370880127ms\n",
    "    predict total time: 137.58182525634766 ms\n",
    "    l2_error, U:  0.7190401305154112 , V:  0.7173188474021113 , P:  0.9807884344618322 , Total:  0.7432489940800948\n",
    "==================================================================================================\n",
    "......\n",
    ".....\n",
    "loss: 0.000172\n",
    "step: 29000, time elapsed: 87.26811408996582ms\n",
    "    predict total time: 121.50454521179199 ms\n",
    "    l2_error, U:  0.030043695657698256 , V:  0.02123015788094162 , P:  0.05539040596455253 , Total:  0.029547291823711123\n",
    "==================================================================================================\n",
    "loss: 0.000119\n",
    "step: 30000, time elapsed: 89.66708183288574ms\n",
    "    predict total time: 171.91457748413086 ms\n",
    "    l2_error, U:  0.015388734902569713 , V:  0.012925750524951195 , P:  0.04789422732887809 , Total:  0.019331853743076763\n",
    "==================================================================================================\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import visualization\n",
    "\n",
    "# visualization\n",
    "visualization(model=model, step=config[\"train_steps\"], input_data=inputs, label=label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![time-error](./images/TimeError_30000.png \"error after training\")\n",
    "\n",
    "As the speed tends to decrease exponentially, the error becomes larger with time, but the overall is within the 5% error range. Picture below shows u, v, p during the process.\n",
    "\n",
    "![mid_stage](./images/mid_stage.png \"mid stage status\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55cde14d23a44784ae1a8ec18da2253dd69c1bd4d69757e4b4870283359a8176"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
