{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于PINNs方法求解Navier-Stokes方程，准确仿2DTaylor-Green涡流动\n",
    "\n",
    "## 概述\n",
    "\n",
    "在流体力学中，Taylor-Green涡流动是一种不稳定的衰减的涡流，在二维周期性边界条件时存在精确解，物理启发的神经网络方法（Physics-informed Neural Networks），以下简称PINNs，通过使用逼近控制方程的损失函数以及简单的网络构型，为快速求解复杂流体问题提供了新的方法。本案例将基于PINNs方法实现二维Taylor-Green涡流动的仿真。\n",
    "\n",
    "## 2维不可压缩纳维-斯托克斯方程（Navier-Stokes equation）\n",
    "\n",
    "纳维-斯托克斯方程（Navier-Stokes equation），简称`N-S`方程，是流体力学领域的经典偏微分方程，在粘性不可压缩情况下，无量纲`N-S`方程的形式如下：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u} {\\partial t} + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y} = - \\frac{\\partial p}{\\partial x} + \\frac{1} {Re} (\\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial v} {\\partial t} + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} = - \\frac{\\partial p}{\\partial y} + \\frac{1} {Re} (\\frac{\\partial^2v}{\\partial x^2} + \\frac{\\partial^2v}{\\partial y^2})\n",
    "$$\n",
    "\n",
    "其中，`Re`表示雷诺数。\n",
    "\n",
    "本案例利用PINNs方法学习位置和时间到相应流场物理量的映射，实现`N-S`方程的求解：\n",
    "\n",
    "$$\n",
    "(x, y, t) \\mapsto (u, v, p)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术路径\n",
    "\n",
    "MindFlow求解该问题的具体流程如下：\n",
    "\n",
    "1. 创建数据集。\n",
    "2. 构建模型。\n",
    "3. 自适应损失的多任务学习。\n",
    "4. 优化器。\n",
    "5. 问题建模。\n",
    "6. 模型训练。\n",
    "7. 模型推理及可视化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sympy\n",
    "import mindspore\n",
    "from mindspore import context, nn, ops, jit, set_seed\n",
    "from mindspore import numpy as mnp\n",
    "\n",
    "from mindflow.cell import MultiScaleFCCell\n",
    "from mindflow.loss import MTLWeightedLossCell\n",
    "from mindflow.utils import load_yaml_config\n",
    "from mindflow.pde import NavierStokes, sympy_to_mindspore\n",
    "\n",
    "from src import create_training_dataset, create_test_dataset, calculate_l2_error, NavierStokes2D\n",
    "\n",
    "set_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\", device_id=0, save_graphs=False)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "config = load_yaml_config('taylor_green_2D.yaml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集\n",
    "\n",
    "训练数据集通过create_training_dataset函数导入，数据集分为区域内数据点、初始条件点、边界条件点,即['time_rect_domain_points', 'time_rect_IC_points', 'time_rect_BC_points']，均采用mindflow.geometry相应接口采样，内容在/src/dataset.py中的create_training_dataset函数中。\n",
    "\n",
    "测试数据集通过create_test_dataset函数导入。本案例使用 **J Kim, P Moin,Application of a fractional-step method to incompressible Navier-Stokes equations,Journal of Computational Physics,Volume 59, Issue 2,1985**中给出的精确解构建验证集。\n",
    "\n",
    "本案例考虑一个大小为$2\\pi \\times 2\\pi$的正方形区域在$ t \\in (0,2)$时段的aylor-Green涡流动仿真。该问题的精确解为：\n",
    "\n",
    "$$\n",
    "u(x,y,t) = -cos(x)sin(y)e^{-2t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v(x,y,t) = sin(x)cos(y)e^{-2t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x,y,t) = -0.25(cos(2x)+cos(2y))e^{-4t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "taylor_dataset = create_training_dataset(config)\n",
    "train_dataset = taylor_dataset.create_dataset(batch_size=config[\"train_batch_size\"],\n",
    "                                              shuffle=True,\n",
    "                                              prebatched_data=True,\n",
    "                                              drop_remainder=True)\n",
    "\n",
    "# create test dataset\n",
    "inputs, label = create_test_dataset(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "\n",
    "本示例使用一个简单的全连接网络，深度为6层，每层128个神经元，激活函数是tanh函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_min = np.array(config[\"geometry\"][\"coord_min\"] + [config[\"geometry\"][\"time_min\"]]).astype(np.float32)\n",
    "coord_max = np.array(config[\"geometry\"][\"coord_max\"] + [config[\"geometry\"][\"time_max\"]]).astype(np.float32)\n",
    "input_center = list(0.5 * (coord_max + coord_min))\n",
    "input_scale = list(2.0 / (coord_max - coord_min))\n",
    "\n",
    "model = MultiScaleFCCell(in_channels=config[\"model\"][\"in_channels\"],\n",
    "                         out_channels=config[\"model\"][\"out_channels\"],\n",
    "                         layers=config[\"model\"][\"layers\"],\n",
    "                         neurons=config[\"model\"][\"neurons\"],\n",
    "                         residual=config[\"model\"][\"residual\"],\n",
    "                         act='tanh',\n",
    "                         num_scales=1,\n",
    "                         input_scale=input_scale,\n",
    "                         input_center=input_center)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自适应损失的多任务学习\n",
    "\n",
    "同一时间，基于PINNs的方法需要优化多个loss，给优化过程带来的巨大的挑战。我们采用**Kendall, Alex, Yarin Gal, and Roberto Cipolla. \"Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.\" CVPR, 2018.** 论文中提出的不确定性权重算法动态调整权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use MtlWeightedLossCell, num loss: 3\n"
     ]
    }
   ],
   "source": [
    "mtl = MTLWeightedLossCell(num_losses=taylor_dataset.num_dataset)\n",
    "print(\"Use MtlWeightedLossCell, num loss: {}\".format(mtl.num_losses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.trainable_params() + mtl.trainable_params()\n",
    "optimizer = nn.Adam(params, learning_rate=config[\"optimizer\"][\"initial_lr\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NavierStokes2D\n",
    "\n",
    "下述NavierStokes2D将圆柱绕流问题同数据集关联起来，包含3个部分：控制方程，边界条件和初始条件。控制方程在mindflow.pde中实现，边界条件与初始条件也是根据上述论文中的解析解实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavierStokes2D(NavierStokes):\n",
    "    def __init__(self, model, re=100, loss_fn=nn.MSELoss()):\n",
    "        super(NavierStokes2D, self).__init__(model, re=re, loss_fn=loss_fn)\n",
    "        self.ic_nodes = sympy_to_mindspore(self.ic(), self.in_vars, self.out_vars)\n",
    "        self.bc_nodes = sympy_to_mindspore(self.bc(), self.in_vars, self.out_vars)\n",
    "\n",
    "    def ic(self):\n",
    "        \"\"\"\n",
    "        Define initial condition equations based on sympy, abstract method.\n",
    "        \"\"\"\n",
    "        ic_u = self.u + sympy.cos(self.x) * sympy.sin(self.y)\n",
    "        ic_v = self.v - sympy.sin(self.x) * sympy.cos(self.y)\n",
    "        ic_p = self.p + 0.25 * (sympy.cos(2*self.x) + sympy.cos(2*self.y))\n",
    "        equations = {\"ic_u\": ic_u, \"ic_v\": ic_v, \"ic_p\": ic_p}\n",
    "        return equations\n",
    "\n",
    "    def bc(self):\n",
    "        \"\"\"\n",
    "        Define boundary condition equations based on sympy, abstract method.\n",
    "        \"\"\"\n",
    "        bc_u = self.u + sympy.cos(self.x) * sympy.sin(self.y) * sympy.exp(-2*self.t)\n",
    "        bc_v = self.v - sympy.sin(self.x) * sympy.cos(self.y) * sympy.exp(-2*self.t)\n",
    "        bc_p = self.p + 0.25 * (sympy.cos(2*self.x) + sympy.cos(2*self.y)) * sympy.exp(-4*self.t)\n",
    "        equations = {\"bc_u\": bc_u, \"bc_v\": bc_v, \"bc_p\": bc_p}\n",
    "        return equations\n",
    "\n",
    "    def get_loss(self, pde_data, ic_data, bc_data):\n",
    "        \"\"\"\n",
    "        Compute loss of 3 parts: governing equation, initial condition and boundary conditions.\n",
    "\n",
    "        Args:\n",
    "            pde_data (Tensor): the input data of governing equations.\n",
    "            ic_data (Tensor): the input data of initial condition.\n",
    "            bc_data (Tensor): the input data of boundary condition.\n",
    "        \"\"\"\n",
    "        pde_res = self.parse_node(self.pde_nodes, inputs=pde_data)\n",
    "        pde_residual = ops.Concat(1)(pde_res)\n",
    "        pde_loss = self.loss_fn(pde_residual, mnp.zeros_like(pde_residual))\n",
    "\n",
    "        ic_res = self.parse_node(self.ic_nodes, inputs=ic_data)\n",
    "        ic_residual = ops.Concat(1)(ic_res)\n",
    "        ic_loss = self.loss_fn(ic_residual, mnp.zeros_like(ic_residual))\n",
    "\n",
    "        bc_res = self.parse_node(self.bc_nodes, inputs=bc_data)\n",
    "        bc_residual = ops.Concat(1)(bc_res)\n",
    "        bc_loss = self.loss_fn(bc_residual, mnp.zeros_like(bc_residual))\n",
    "\n",
    "        return pde_loss + ic_loss + bc_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "使用MindSpore>= 2.0.0的版本，可以使用函数式编程范式训练神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    problem = NavierStokes2D(model, re=config[\"Re\"])\n",
    "\n",
    "    if use_ascend:\n",
    "        from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "        loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "        auto_mixed_precision(model, 'O3')\n",
    "\n",
    "    def forward_fn(pde_data, ic_data, bc_data):\n",
    "        loss = problem.get_loss(pde_data, ic_data, bc_data)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.scale(loss)\n",
    "        return loss\n",
    "\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "\n",
    "    @jit\n",
    "    def train_step(pde_data, ic_data, bc_data):\n",
    "        loss, grads = grad_fn(pde_data, ic_data, bc_data)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.unscale(loss)\n",
    "            if all_finite(grads):\n",
    "                grads = loss_scaler.unscale(grads)\n",
    "                loss = ops.depend(loss, optimizer(grads))\n",
    "        else:\n",
    "            loss = ops.depend(loss, optimizer(grads))\n",
    "        return loss\n",
    "\n",
    "    steps = config[\"train_steps\"]\n",
    "\n",
    "    sink_process = mindspore.data_sink(train_step, train_dataset, sink_size=1)\n",
    "    model.set_train()\n",
    "    for step in range(steps + 1):\n",
    "        local_time_beg = time.time()\n",
    "        cur_loss = sink_process()\n",
    "        if step % 1000 == 0:\n",
    "            print(f\"loss: {cur_loss.asnumpy():>7f}\")\n",
    "            print(\"step: {}, time elapsed: {}ms\".format(step, (time.time() - local_time_beg) * 1000))\n",
    "            calculate_l2_error(model, inputs, label, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_beg = time.time()\n",
    "train()\n",
    "print(\"End-to-End total time: {} s\".format(time.time() - time_beg))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "check training dataset size:  128\n",
    "Use MtlWeightedLossCell, num loss: 3\n",
    "momentum_x: u(x, y, t)*Derivative(u(x, y, t), x) + v(x, y, t)*Derivative(u(x, y, t), y) + Derivative(p(x, y, t), x) + Derivative(u(x, y, t), t) - 1.0*Derivative(u(x, y, t), (x, 2)) - 1.0*Derivative(u(x, y, t), (y, 2))\n",
    "    Item numbers of current derivative formula nodes: 6\n",
    "momentum_y: u(x, y, t)*Derivative(v(x, y, t), x) + v(x, y, t)*Derivative(v(x, y, t), y) + Derivative(p(x, y, t), y) + Derivative(v(x, y, t), t) - 1.0*Derivative(v(x, y, t), (x, 2)) - 1.0*Derivative(v(x, y, t), (y, 2))\n",
    "    Item numbers of current derivative formula nodes: 6\n",
    "continuty: Derivative(u(x, y, t), x) + Derivative(v(x, y, t), y)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "ic_u: u(x, y, t) + sin(y)*cos(x)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "ic_v: v(x, y, t) - sin(x)*cos(y)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "ic_p: p(x, y, t) + 0.25*cos(2*x) + 0.25*cos(2*y)\n",
    "    Item numbers of current derivative formula nodes: 3\n",
    "bc_u: u(x, y, t) + exp(-2*t)*sin(y)*cos(x)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "bc_v: v(x, y, t) - exp(-2*t)*sin(x)*cos(y)\n",
    "    Item numbers of current derivative formula nodes: 2\n",
    "bc_p: p(x, y, t) + 0.25*exp(-4*t)*cos(2*x) + 0.25*exp(-4*t)*cos(2*y)\n",
    "    Item numbers of current derivative formula nodes: 3\n",
    "loss: 0.218985\n",
    "step: 0, time elapsed: 8551.078081130981ms\n",
    "    predict total time: 395.74146270751953 ms\n",
    "    l2_error, U:  1.0272722185259853 , V:  1.0068734156826729 , P:  1.1140811724988493 , Total:  1.025431141488198\n",
    "==================================================================================================\n",
    "loss: 0.117311\n",
    "step: 1000, time elapsed: 96.29058837890625ms\n",
    "    predict total time: 177.2327423095703 ms\n",
    "    l2_error, U:  0.7230177964964256 , V:  0.7154075373127421 , P:  1.0178466945703284 , Total:  0.7482490912542953\n",
    "==================================================================================================\n",
    "loss: 0.119411\n",
    "step: 2000, time elapsed: 89.85757827758789ms\n",
    "    predict total time: 143.2340145111084 ms\n",
    "    l2_error, U:  0.7112490531604364 , V:  0.7168233752672813 , P:  1.0153781956196177 , Total:  0.7434033117415322\n",
    "==================================================================================================\n",
    "loss: 0.116417\n",
    "step: 3000, time elapsed: 88.8054370880127ms\n",
    "    predict total time: 137.58182525634766 ms\n",
    "    l2_error, U:  0.7190401305154112 , V:  0.7173188474021113 , P:  0.9807884344618322 , Total:  0.7432489940800948\n",
    "==================================================================================================\n",
    "......\n",
    ".....\n",
    "loss: 0.000172\n",
    "step: 29000, time elapsed: 87.26811408996582ms\n",
    "    predict total time: 121.50454521179199 ms\n",
    "    l2_error, U:  0.030043695657698256 , V:  0.02123015788094162 , P:  0.05539040596455253 , Total:  0.029547291823711123\n",
    "==================================================================================================\n",
    "loss: 0.000119\n",
    "step: 30000, time elapsed: 89.66708183288574ms\n",
    "    predict total time: 171.91457748413086 ms\n",
    "    l2_error, U:  0.015388734902569713 , V:  0.012925750524951195 , P:  0.04789422732887809 , Total:  0.019331853743076763\n",
    "==================================================================================================\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练结果即可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import visualization\n",
    "\n",
    "# visualization\n",
    "visualization(model=model, step=config[\"train_steps\"], input_data=inputs, label=label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Time_error](./images/TimeError_30000.png \"error after training\")\n",
    "\n",
    "因速度呈指数下降的趋势，随着时间推移，误差变大，但整体处于5%的误差范围内。下方图片展示了中间过程中各指标的情况。\n",
    "\n",
    "![mid_stage](./images/mid_stage.png \"mid stage status\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55cde14d23a44784ae1a8ec18da2253dd69c1bd4d69757e4b4870283359a8176"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
