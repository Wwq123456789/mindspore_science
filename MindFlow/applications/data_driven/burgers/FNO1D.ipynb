{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Solve Burgers' equation based on Fourier Neural Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "Computational fluid dynamics is one of the most important techniques in the field of fluid mechanics in the 21st century. The flow analysis, prediction and control can be realized by solving the governing equations of fluid mechanics by numerical method. Traditional finite element method (FEM) and finite difference method (FDM) are inefficient because of the complex simulation process (physical modeling, meshing, numerical discretization, iterative solution, etc.) and high computing costs. Therefore, it is necessary to improve the efficiency of fluid simulation with AI.\n",
    "\n",
    "Machine learning methods provide a new paradigm for scientific computing by providing a fast solver similar to traditional methods. Classical neural networks learn mappings between finite dimensional spaces and can only learn solutions related to a specific discretization. Different from traditional neural networks, Fourier Neural Operator (FNO) is a new deep learning architecture that can learn mappings between infinite-dimensional function spaces. It directly learns mappings from arbitrary function parameters to solutions to solve a class of partial differential equations.  Therefore, it has a stronger generalization capability. More information can be found in the paper, [Fourier Neural Operator for Parametric Partial Differential Equations](https://arxiv.org/abs/2010.08895).\n",
    "\n",
    "This tutorial describes how to solve the 1-d Burgers' equation using Fourier neural operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Burgers' equation\n",
    "\n",
    "The 1-d Burgersâ€™ equation is a non-linear PDE with various applications including modeling the one\n",
    "dimensional flow of a viscous fluid. It takes the form\n",
    "\n",
    "$$\n",
    "\\partial_t u(x, t)+\\partial_x (u^2(x, t)/2)=\\nu \\partial_{xx} u(x, t), \\quad x \\in(0,1), t \\in(0, 1]\n",
    "$$\n",
    "\n",
    "$$\n",
    "u(x, 0)=u_0(x), \\quad x \\in(0,1)\n",
    "$$\n",
    "\n",
    "where $u$ is the velocity field, $u_0$ is the initial condition and $\\nu$ is the viscosity coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import context, nn, Tensor, set_seed\n",
    "from mindspore import DynamicLossScaleManager, LossMonitor, TimeMonitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindflow import FNO1D, RelativeRMSELoss, Solver, load_yaml_config, get_warmup_cosine_annealing_lr\n",
    "\n",
    "from src import PredictCallback, create_training_dataset\n",
    "\n",
    "\n",
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "context.set_context(mode=context.GRAPH_MODE, device_target='GPU', device_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = load_yaml_config(\"burgers1d.yaml\")\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]\n",
    "callback_params = config[\"callback\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training Dataset Construction\n",
    "\n",
    "Download the training and test dataset: [data_driven/burgers/dataset](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/burgers/dataset/) .\n",
    "\n",
    "In this case, random sampling is performed according to the solution domain, initial condition and boundary value condition to generate training data sets. The specific settings are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation finished\n",
      "input_path:  (1000, 1024, 1)\n",
      "label_path:  (1000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# create training dataset\n",
    "train_dataset = create_training_dataset(data_params, shuffle=True)\n",
    "\n",
    "# create test dataset\n",
    "test_input, test_label = np.load(os.path.join(data_params[\"path\"], \"test/inputs.npy\")), \\\n",
    "                         np.load(os.path.join(data_params[\"path\"], \"test/label.npy\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Construction\n",
    "\n",
    "This example uses a simple fully-connected network with a depth of 4 layers and the activation function is the `tanh` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = FNO1D(in_channels=model_params[\"in_channels\"],\n",
    "              out_channels=model_params[\"out_channels\"],\n",
    "              resolution=model_params[\"resolution\"],\n",
    "              modes=model_params[\"modes\"],\n",
    "              channels=model_params[\"width\"],\n",
    "              depth=model_params[\"depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = train_dataset.get_dataset_size()\n",
    "lr = get_warmup_cosine_annealing_lr(lr_init=optimizer_params[\"initial_lr\"],\n",
    "                                    last_epoch=optimizer_params[\"train_epochs\"],\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    warmup_epochs=1)\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=Tensor(lr))\n",
    "loss_scale = DynamicLossScaleManager()\n",
    "\n",
    "loss_fn = RelativeRMSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "solver = Solver(model,\n",
    "                optimizer=optimizer,\n",
    "                loss_scale_manager=loss_scale,\n",
    "                loss_fn=loss_fn,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./FNO1D\n",
      "check test dataset shape: (200, 1024, 1), (200, 1024)\n"
     ]
    }
   ],
   "source": [
    "summary_dir = os.path.join(callback_params[\"summary_dir\"], \"FNO1D\")\n",
    "print(summary_dir)\n",
    "pred_cb = PredictCallback(model=model,\n",
    "                          inputs=test_input,\n",
    "                          label=test_label,\n",
    "                          config=config,\n",
    "                          summary_dir=summary_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Invoke the Solver interface for model training and callback interface for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 125, loss is 2.377823\n",
      "Train epoch time: 5782.938 ms, per step time: 46.264 ms\n",
      "epoch: 2 step: 125, loss is 0.88470775\n",
      "Train epoch time: 1150.446 ms, per step time: 9.204 ms\n",
      "epoch: 3 step: 125, loss is 0.98071647\n",
      "Train epoch time: 1135.464 ms, per step time: 9.084 ms\n",
      "epoch: 4 step: 125, loss is 0.5404751\n",
      "Train epoch time: 1114.245 ms, per step time: 8.914 ms\n",
      "epoch: 5 step: 125, loss is 0.39976493\n",
      "Train epoch time: 1125.107 ms, per step time: 9.001 ms\n",
      "epoch: 6 step: 125, loss is 0.508416\n",
      "Train epoch time: 1127.477 ms, per step time: 9.020 ms\n",
      "epoch: 7 step: 125, loss is 0.42839915\n",
      "Train epoch time: 1125.775 ms, per step time: 9.006 ms\n",
      "epoch: 8 step: 125, loss is 0.28270185\n",
      "Train epoch time: 1118.428 ms, per step time: 8.947 ms\n",
      "epoch: 9 step: 125, loss is 0.24137405\n",
      "Train epoch time: 1121.705 ms, per step time: 8.974 ms\n",
      "epoch: 10 step: 125, loss is 0.22623646\n",
      "Train epoch time: 1118.699 ms, per step time: 8.950 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.03270653011277318\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 1.7423865795135498 s\n",
      "epoch: 11 step: 125, loss is 0.33585945\n",
      "Train epoch time: 1117.997 ms, per step time: 8.944 ms\n",
      "epoch: 12 step: 125, loss is 0.25731388\n",
      "Train epoch time: 1120.077 ms, per step time: 8.961 ms\n",
      "epoch: 13 step: 125, loss is 0.20313437\n",
      "Train epoch time: 1128.541 ms, per step time: 9.028 ms\n",
      "epoch: 14 step: 125, loss is 0.22666724\n",
      "Train epoch time: 1117.210 ms, per step time: 8.938 ms\n",
      "epoch: 15 step: 125, loss is 0.20906028\n",
      "Train epoch time: 1120.776 ms, per step time: 8.966 ms\n",
      "epoch: 16 step: 125, loss is 0.25133124\n",
      "Train epoch time: 1115.006 ms, per step time: 8.920 ms\n",
      "epoch: 17 step: 125, loss is 0.23385246\n",
      "Train epoch time: 1110.570 ms, per step time: 8.885 ms\n",
      "epoch: 18 step: 125, loss is 0.15110934\n",
      "Train epoch time: 1113.885 ms, per step time: 8.911 ms\n",
      "epoch: 19 step: 125, loss is 0.14757131\n",
      "Train epoch time: 1125.028 ms, per step time: 9.000 ms\n",
      "epoch: 20 step: 125, loss is 0.17006263\n",
      "Train epoch time: 1112.923 ms, per step time: 8.903 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.027247884799726306\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5151116847991943 s\n",
      "epoch: 21 step: 125, loss is 0.1538753\n",
      "Train epoch time: 1139.767 ms, per step time: 9.118 ms\n",
      "epoch: 22 step: 125, loss is 0.16818231\n",
      "Train epoch time: 1111.397 ms, per step time: 8.891 ms\n",
      "epoch: 23 step: 125, loss is 0.1970831\n",
      "Train epoch time: 1126.973 ms, per step time: 9.016 ms\n",
      "epoch: 24 step: 125, loss is 0.20690475\n",
      "Train epoch time: 1113.934 ms, per step time: 8.911 ms\n",
      "epoch: 25 step: 125, loss is 0.13336918\n",
      "Train epoch time: 1112.561 ms, per step time: 8.900 ms\n",
      "epoch: 26 step: 125, loss is 0.23019765\n",
      "Train epoch time: 1101.155 ms, per step time: 8.809 ms\n",
      "epoch: 27 step: 125, loss is 0.123824425\n",
      "Train epoch time: 1120.251 ms, per step time: 8.962 ms\n",
      "epoch: 28 step: 125, loss is 0.173518\n",
      "Train epoch time: 1114.455 ms, per step time: 8.916 ms\n",
      "epoch: 29 step: 125, loss is 0.261164\n",
      "Train epoch time: 1112.732 ms, per step time: 8.902 ms\n",
      "epoch: 30 step: 125, loss is 0.13786153\n",
      "Train epoch time: 1120.265 ms, per step time: 8.962 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.01836740570142865\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5344314575195312 s\n",
      "epoch: 31 step: 125, loss is 0.13023803\n",
      "Train epoch time: 1122.912 ms, per step time: 8.983 ms\n",
      "epoch: 32 step: 125, loss is 0.123938166\n",
      "Train epoch time: 1107.470 ms, per step time: 8.860 ms\n",
      "epoch: 33 step: 125, loss is 0.20266412\n",
      "Train epoch time: 1117.588 ms, per step time: 8.941 ms\n",
      "epoch: 34 step: 125, loss is 0.14180553\n",
      "Train epoch time: 1106.041 ms, per step time: 8.848 ms\n",
      "epoch: 35 step: 125, loss is 0.14417762\n",
      "Train epoch time: 1122.555 ms, per step time: 8.980 ms\n",
      "epoch: 36 step: 125, loss is 0.19346556\n",
      "Train epoch time: 1108.443 ms, per step time: 8.868 ms\n",
      "epoch: 37 step: 125, loss is 0.1840501\n",
      "Train epoch time: 1111.599 ms, per step time: 8.893 ms\n",
      "epoch: 38 step: 125, loss is 0.15954982\n",
      "Train epoch time: 1107.613 ms, per step time: 8.861 ms\n",
      "epoch: 39 step: 125, loss is 0.10465436\n",
      "Train epoch time: 1117.095 ms, per step time: 8.937 ms\n",
      "epoch: 40 step: 125, loss is 0.114137515\n",
      "Train epoch time: 1117.687 ms, per step time: 8.941 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.016485637917649\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.4984111785888672 s\n",
      "epoch: 41 step: 125, loss is 0.14426222\n",
      "Train epoch time: 1118.713 ms, per step time: 8.950 ms\n",
      "epoch: 42 step: 125, loss is 0.1350481\n",
      "Train epoch time: 1111.951 ms, per step time: 8.896 ms\n",
      "epoch: 43 step: 125, loss is 0.10679893\n",
      "Train epoch time: 1118.283 ms, per step time: 8.946 ms\n",
      "epoch: 44 step: 125, loss is 0.13426436\n",
      "Train epoch time: 1118.157 ms, per step time: 8.945 ms\n",
      "epoch: 45 step: 125, loss is 0.113091685\n",
      "Train epoch time: 1113.948 ms, per step time: 8.912 ms\n",
      "epoch: 46 step: 125, loss is 0.10835588\n",
      "Train epoch time: 1115.083 ms, per step time: 8.921 ms\n",
      "epoch: 47 step: 125, loss is 0.13707519\n",
      "Train epoch time: 1124.944 ms, per step time: 9.000 ms\n",
      "epoch: 48 step: 125, loss is 0.095591605\n",
      "Train epoch time: 1122.857 ms, per step time: 8.983 ms\n",
      "epoch: 49 step: 125, loss is 0.09948881\n",
      "Train epoch time: 1121.644 ms, per step time: 8.973 ms\n",
      "epoch: 50 step: 125, loss is 0.08291495\n",
      "Train epoch time: 1113.774 ms, per step time: 8.910 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.015063997637480498\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.49147462844848633 s\n",
      "epoch: 51 step: 125, loss is 0.096910805\n",
      "Train epoch time: 1121.679 ms, per step time: 8.973 ms\n",
      "epoch: 52 step: 125, loss is 0.07296389\n",
      "Train epoch time: 1111.681 ms, per step time: 8.893 ms\n",
      "epoch: 53 step: 125, loss is 0.08109884\n",
      "Train epoch time: 1105.117 ms, per step time: 8.841 ms\n",
      "epoch: 54 step: 125, loss is 0.07857765\n",
      "Train epoch time: 1113.886 ms, per step time: 8.911 ms\n",
      "epoch: 55 step: 125, loss is 0.13214406\n",
      "Train epoch time: 1118.345 ms, per step time: 8.947 ms\n",
      "epoch: 56 step: 125, loss is 0.09048429\n",
      "Train epoch time: 1108.117 ms, per step time: 8.865 ms\n",
      "epoch: 57 step: 125, loss is 0.08492902\n",
      "Train epoch time: 1111.194 ms, per step time: 8.890 ms\n",
      "epoch: 58 step: 125, loss is 0.06460292\n",
      "Train epoch time: 1115.370 ms, per step time: 8.923 ms\n",
      "epoch: 59 step: 125, loss is 0.07572392\n",
      "Train epoch time: 1118.374 ms, per step time: 8.947 ms\n",
      "epoch: 60 step: 125, loss is 0.069739655\n",
      "Train epoch time: 1108.569 ms, per step time: 8.869 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.009847545691300183\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5194306373596191 s\n",
      "epoch: 61 step: 125, loss is 0.05091487\n",
      "Train epoch time: 1122.071 ms, per step time: 8.977 ms\n",
      "epoch: 62 step: 125, loss is 0.054475456\n",
      "Train epoch time: 1124.192 ms, per step time: 8.994 ms\n",
      "epoch: 63 step: 125, loss is 0.09270928\n",
      "Train epoch time: 1118.681 ms, per step time: 8.949 ms\n",
      "epoch: 64 step: 125, loss is 0.058242366\n",
      "Train epoch time: 1107.830 ms, per step time: 8.863 ms\n",
      "epoch: 65 step: 125, loss is 0.06275006\n",
      "Train epoch time: 1103.584 ms, per step time: 8.829 ms\n",
      "epoch: 66 step: 125, loss is 0.053316012\n",
      "Train epoch time: 1111.706 ms, per step time: 8.894 ms\n",
      "epoch: 67 step: 125, loss is 0.04314721\n",
      "Train epoch time: 1121.986 ms, per step time: 8.976 ms\n",
      "epoch: 68 step: 125, loss is 0.057664156\n",
      "Train epoch time: 1117.760 ms, per step time: 8.942 ms\n",
      "epoch: 69 step: 125, loss is 0.09109219\n",
      "Train epoch time: 1123.288 ms, per step time: 8.986 ms\n",
      "epoch: 70 step: 125, loss is 0.07522475\n",
      "Train epoch time: 1126.453 ms, per step time: 9.012 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.00840939896297641\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5309998989105225 s\n",
      "epoch: 71 step: 125, loss is 0.05523804\n",
      "Train epoch time: 1132.706 ms, per step time: 9.062 ms\n",
      "epoch: 72 step: 125, loss is 0.04375055\n",
      "Train epoch time: 1128.408 ms, per step time: 9.027 ms\n",
      "epoch: 73 step: 125, loss is 0.04897921\n",
      "Train epoch time: 1129.312 ms, per step time: 9.034 ms\n",
      "epoch: 74 step: 125, loss is 0.044511348\n",
      "Train epoch time: 1113.304 ms, per step time: 8.906 ms\n",
      "epoch: 75 step: 125, loss is 0.05049017\n",
      "Train epoch time: 1121.703 ms, per step time: 8.974 ms\n",
      "epoch: 76 step: 125, loss is 0.070644744\n",
      "Train epoch time: 1103.994 ms, per step time: 8.832 ms\n",
      "epoch: 77 step: 125, loss is 0.048485912\n",
      "Train epoch time: 1106.925 ms, per step time: 8.855 ms\n",
      "epoch: 78 step: 125, loss is 0.06378794\n",
      "Train epoch time: 1111.030 ms, per step time: 8.888 ms\n",
      "epoch: 79 step: 125, loss is 0.043206975\n",
      "Train epoch time: 1118.369 ms, per step time: 8.947 ms\n",
      "epoch: 80 step: 125, loss is 0.034759518\n",
      "Train epoch time: 1109.555 ms, per step time: 8.876 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.007532734228298068\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5164434909820557 s\n",
      "epoch: 81 step: 125, loss is 0.035872735\n",
      "Train epoch time: 1108.335 ms, per step time: 8.867 ms\n",
      "epoch: 82 step: 125, loss is 0.034446612\n",
      "Train epoch time: 1114.836 ms, per step time: 8.919 ms\n",
      "epoch: 83 step: 125, loss is 0.035888225\n",
      "Train epoch time: 1114.682 ms, per step time: 8.917 ms\n",
      "epoch: 84 step: 125, loss is 0.04184662\n",
      "Train epoch time: 1106.532 ms, per step time: 8.852 ms\n",
      "epoch: 85 step: 125, loss is 0.037143923\n",
      "Train epoch time: 1113.278 ms, per step time: 8.906 ms\n",
      "epoch: 86 step: 125, loss is 0.048543468\n",
      "Train epoch time: 1127.045 ms, per step time: 9.016 ms\n",
      "epoch: 87 step: 125, loss is 0.04336884\n",
      "Train epoch time: 1115.179 ms, per step time: 8.921 ms\n",
      "epoch: 88 step: 125, loss is 0.040960975\n",
      "Train epoch time: 1121.686 ms, per step time: 8.973 ms\n",
      "epoch: 89 step: 125, loss is 0.033356074\n",
      "Train epoch time: 1119.293 ms, per step time: 8.954 ms\n",
      "epoch: 90 step: 125, loss is 0.028824337\n",
      "Train epoch time: 1135.977 ms, per step time: 9.088 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.005890031687449664\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5012176036834717 s\n",
      "epoch: 91 step: 125, loss is 0.026378194\n",
      "Train epoch time: 1119.095 ms, per step time: 8.953 ms\n",
      "epoch: 92 step: 125, loss is 0.057838168\n",
      "Train epoch time: 1116.712 ms, per step time: 8.934 ms\n",
      "epoch: 93 step: 125, loss is 0.034773324\n",
      "Train epoch time: 1107.931 ms, per step time: 8.863 ms\n",
      "epoch: 94 step: 125, loss is 0.029720988\n",
      "Train epoch time: 1109.336 ms, per step time: 8.875 ms\n",
      "epoch: 95 step: 125, loss is 0.02933883\n",
      "Train epoch time: 1111.804 ms, per step time: 8.894 ms\n",
      "epoch: 96 step: 125, loss is 0.03140598\n",
      "Train epoch time: 1116.788 ms, per step time: 8.934 ms\n",
      "epoch: 97 step: 125, loss is 0.03695058\n",
      "Train epoch time: 1115.020 ms, per step time: 8.920 ms\n",
      "epoch: 98 step: 125, loss is 0.039841708\n",
      "Train epoch time: 1120.316 ms, per step time: 8.963 ms\n",
      "epoch: 99 step: 125, loss is 0.039001673\n",
      "Train epoch time: 1134.618 ms, per step time: 9.077 ms\n",
      "epoch: 100 step: 125, loss is 0.038434036\n",
      "Train epoch time: 1116.549 ms, per step time: 8.932 ms\n",
      "================================Start Evaluation================================\n",
      "mean rms_error: 0.005707952339434996\n",
      "=================================End Evaluation=================================\n",
      "predict total time: 0.5055065155029297 s\n"
     ]
    }
   ],
   "source": [
    "solver.train(epoch=optimizer_params[\"train_epochs\"],\n",
    "             train_dataset=train_dataset,\n",
    "             callbacks=[LossMonitor(), TimeMonitor(), pred_cb],\n",
    "             dataset_sink_mode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "57ace93c29d9374277a79956c3f1b916d7d9a05468d906842f9921d0d494a29f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
